#data.matrix[ , apply(data.matrix, 2, var) != 0]
pca <- prcomp(t(data.matrix),scale.=TRUE, center=TRUE)
## calculate the percentage of variation that each PC accounts for...
pca.var <- pca$sdev^2
pca.var.per <- round(pca.var/sum(pca.var)*100, 1)
pca.var.per
## now make a fancy looking plot that shows the PCs and the variation:
pca.data <- data.frame(Sample=rownames(pca$x),
X=pca$x[,1],
Y=pca$x[,2])
pca.data
ggplot(data=pca.data, aes(x=X, y=Y, label=Sample)) +
geom_text() +
xlab(paste("PC1 - ", pca.var.per[1], "%", sep="")) +
ylab(paste("PC2 - ", pca.var.per[2], "%", sep="")) +
theme_bw() +
ggtitle("PCA Graph")
###################################################################
##
## 2) Now draw an MDS plot using the same data and the Euclidean
##    distance. This graph should look the same as the PCA plot
##
###################################################################
## first, calculate the distance matrix using the Euclidian distance.
## NOTE: We are transposing, scaling and centering the data just like PCA.
distance.matrix <- dist(scale(t(data.matrix), center=TRUE, scale=TRUE),
method="euclidean")
## do the MDS math (this is basically eigen value decomposition)
mds.stuff <- cmdscale(distance.matrix, eig=TRUE, x.ret=TRUE)
## calculate the percentage of variation that each MDS axis accounts for...
mds.var.per <- round(mds.stuff$eig/sum(mds.stuff$eig)*100, 1)
mds.var.per
## now make a fancy looking plot that shows the MDS axes and the variation:
mds.values <- mds.stuff$points
mds.data <- data.frame(Sample=rownames(mds.values),
X=mds.values[,1],
Y=mds.values[,2])
mds.data
ggplot(data=mds.data, aes(x=X, y=Y, label=Sample)) +
geom_text() +
theme_bw() +
xlab(paste("MDS1 - ", mds.var.per[1], "%", sep="")) +
ylab(paste("MDS2 - ", mds.var.per[2], "%", sep="")) +
ggtitle("MDS plot using Euclidean distance")
###################################################################
##
## 3) Now draw an MDS plot using the same data and the average log(fold change)
##    This graph should look different than the first two
##
###################################################################
## first, take the log2 of all the values in the data.matrix.
## This makes it easy to compute log2(Fold Change) between a gene in two
## samples since...
##
## log2(Fold Change) = log2(value for sample 1) - log2(value for sample 2)
##
log2.data.matrix <- log2(data.matrix)
## now create an empty distance matrix
log2.distance.matrix <- matrix(0,
nrow=ncol(log2.data.matrix),
ncol=ncol(log2.data.matrix),
dimnames=list(colnames(log2.data.matrix),
colnames(log2.data.matrix)))
log2.distance.matrix
## now compute the distance matrix using avg(absolute value(log2(FC)))
for(i in 1:ncol(log2.distance.matrix)) {
for(j in 1:i) {
log2.distance.matrix[i, j] <-
mean(abs(log2.data.matrix[,i] - log2.data.matrix[,j]))
}
}
log2.distance.matrix
## do the MDS math (this is basically eigen value decomposition)
## cmdscale() is the function for "Classical Multi-Dimensional Scalign"
#mds.stuff <- cmdscale(as.dist(log2.distance.matrix),
#  eig=TRUE,
#  x.ret=TRUE)
## calculate the percentage of variation that each MDS axis accounts for...
mds.var.per <- round(mds.stuff$eig/sum(mds.stuff$eig)*100, 1)
mds.var.per
## now make a fancy looking plot that shows the MDS axes and the variation:
mds.values <- mds.stuff$points
mds.data <- data.frame(Sample=rownames(mds.values),
X=mds.values[,1],
Y=mds.values[,2])
mds.data
ggplot(data=mds.data, aes(x=X, y=Y, label=Sample)) +
geom_text() +
theme_bw() +
xlab(paste("MDS1 - ", mds.var.per[1], "%", sep="")) +
ylab(paste("MDS2 - ", mds.var.per[2], "%", sep="")) +
ggtitle("MDS plot using avg(logFC) as the distance")
data.matrixP=read.csv("/Users/jbrown/Documents/GitHub/BACandBlue/stats help and prelim practice/otu.csv")
data.matrix=merge(data.matrix,data.matrixP)
head(data.matrix)
dim(data.matrix)
#data.matrix$peaks <- NA #ADD COLUMN FOR NON-ZERO VECTOR TO LAND
#data.matrix$peaks[which(data.matrix$Peak_ID<=209)] <- "<=209"
data.matrix$ï..Peak_ID=as.numeric(data.matrix$ï..Peak_ID)
###################################################################
##
## 1) Just for reference, draw a PCA plot using this data...
##
###################################################################
#which(apply(data.matrix, 2, var)==0) ##REMOVE THE ZEROS!
#data.matrix[ , apply(data.matrix, 2, var) != 0]
pca <- prcomp(t(data.matrix),scale.=TRUE, center=TRUE)
data.matrixP=read.csv("/Users/jbrown/Documents/GitHub/BACandBlue/stats help and prelim practice/otu.csv")
data.matrixP=read.csv("/Users/jbrown/Documents/GitHub/BACandBlue/stats help and prelim practice/pantoe20181218.csv")
data.matrixF=read.csv("/Users/jbrown/Documents/GitHub/BACandBlue/stats help and prelim practice/otu.csv")
data.matrixALL=rbind(data.matrixF,data.matrixP)
data.matrixALL=merge(data.matrixF,data.matrixP)
data.matrixP=read.csv("/Users/jbrown/Documents/GitHub/BACandBlue/stats help and prelim practice/pantoe20181218.csv")
data.matrixF=read.csv("/Users/jbrown/Documents/GitHub/BACandBlue/stats help and prelim practice/otu.csv")
data.matrixALL=merge(data.matrixF,data.matrixP)
head(data.matrixALL)
dim(data.matrixALL)
#data.matrixALL$peaks <- NA #ADD COLUMN FOR NON-ZERO VECTOR TO LAND
#data.matrixALL$peaks[which(data.matrixALL$Peak_ID<=209)] <- "<=209"
data.matrixALL$ï..Peak_ID=as.numeric(data.matrixALL$ï..Peak_ID)
###################################################################
##
## 1) Just for reference, draw a PCA plot using this data...
##
###################################################################
#which(apply(data.matrixALL, 2, var)==0) ##REMOVE THE ZEROS!
#data.matrixALL[ , apply(data.matrixALL, 2, var) != 0]
pca <- prcomp(t(data.matrixALL),scale.=TRUE, center=TRUE)
## calculate the percentage of variation that each PC accounts for...
pca.var <- pca$sdev^2
pca.var.per <- round(pca.var/sum(pca.var)*100, 1)
pca.var.per
## now make a fancy looking plot that shows the PCs and the variation:
pca.data <- data.frame(Sample=rownames(pca$x),
X=pca$x[,1],
Y=pca$x[,2])
pca.data
ggplot(data=pca.data, aes(x=X, y=Y, label=Sample)) +
geom_text() +
xlab(paste("PC1 - ", pca.var.per[1], "%", sep="")) +
ylab(paste("PC2 - ", pca.var.per[2], "%", sep="")) +
theme_bw() +
ggtitle("PCA Graph")
###################################################################
##
## 2) Now draw an MDS plot using the same data and the Euclidean
##    distance. This graph should look the same as the PCA plot
##
###################################################################
## first, calculate the distance matrix using the Euclidian distance.
## NOTE: We are transposing, scaling and centering the data just like PCA.
distance.matrix <- dist(scale(t(data.matrixALL), center=TRUE, scale=TRUE),
method="euclidean")
## do the MDS math (this is basically eigen value decomposition)
mds.stuff <- cmdscale(distance.matrix, eig=TRUE, x.ret=TRUE)
## calculate the percentage of variation that each MDS axis accounts for...
mds.var.per <- round(mds.stuff$eig/sum(mds.stuff$eig)*100, 1)
mds.var.per
## now make a fancy looking plot that shows the MDS axes and the variation:
mds.values <- mds.stuff$points
mds.data <- data.frame(Sample=rownames(mds.values),
X=mds.values[,1],
Y=mds.values[,2])
mds.data
ggplot(data=mds.data, aes(x=X, y=Y, label=Sample)) +
geom_text() +
theme_bw() +
xlab(paste("MDS1 - ", mds.var.per[1], "%", sep="")) +
ylab(paste("MDS2 - ", mds.var.per[2], "%", sep="")) +
ggtitle("MDS plot using Euclidean distance")
###################################################################
##
## 3) Now draw an MDS plot using the same data and the average log(fold change)
##    This graph should look different than the first two
##
###################################################################
## first, take the log2 of all the values in the data.matrixALL.
## This makes it easy to compute log2(Fold Change) between a gene in two
## samples since...
##
## log2(Fold Change) = log2(value for sample 1) - log2(value for sample 2)
##
log2.data.matrixALL <- log2(data.matrixALL)
## now create an empty distance matrix
log2.distance.matrix <- matrix(0,
nrow=ncol(log2.data.matrixALL),
ncol=ncol(log2.data.matrixALL),
dimnames=list(colnames(log2.data.matrixALL),
colnames(log2.data.matrixALL)))
log2.distance.matrix
## now compute the distance matrix using avg(absolute value(log2(FC)))
for(i in 1:ncol(log2.distance.matrix)) {
for(j in 1:i) {
log2.distance.matrix[i, j] <-
mean(abs(log2.data.matrixALL[,i] - log2.data.matrixALL[,j]))
}
}
log2.distance.matrix
## do the MDS math (this is basically eigen value decomposition)
## cmdscale() is the function for "Classical Multi-Dimensional Scalign"
#mds.stuff <- cmdscale(as.dist(log2.distance.matrix),
#  eig=TRUE,
#  x.ret=TRUE)
## calculate the percentage of variation that each MDS axis accounts for...
mds.var.per <- round(mds.stuff$eig/sum(mds.stuff$eig)*100, 1)
mds.var.per
## now make a fancy looking plot that shows the MDS axes and the variation:
mds.values <- mds.stuff$points
mds.data <- data.frame(Sample=rownames(mds.values),
X=mds.values[,1],
Y=mds.values[,2])
mds.data
ggplot(data=mds.data, aes(x=X, y=Y, label=Sample)) +
geom_text() +
theme_bw() +
xlab(paste("MDS1 - ", mds.var.per[1], "%", sep="")) +
ylab(paste("MDS2 - ", mds.var.per[2], "%", sep="")) +
ggtitle("MDS plot using avg(logFC) as the distance")
data.matrixP=read.csv("/Users/jbrown/Documents/GitHub/BACandBlue/stats help and prelim practice/pantoe20181218.csv")
data.matrixF=read.csv("/Users/jbrown/Documents/GitHub/BACandBlue/stats help and prelim practice/otu.csv")
data.matrixALL=merge(data.matrixF,data.matrixP)
head(data.matrixALL)
dim(data.matrixALL)
#data.matrixALL$peaks <- NA #ADD COLUMN FOR NON-ZERO VECTOR TO LAND
#data.matrixALL$peaks[which(data.matrixALL$Peak_ID<=209)] <- "<=209"
data.matrixALL$ï..Peak_ID=as.numeric(data.matrixALL$ï..Peak_ID)
###################################################################
##
## 1) Just for reference, draw a PCA plot using this data...
##
###################################################################
#which(apply(data.matrixALL, 2, var)==0) ##REMOVE THE ZEROS!
#data.matrixALL[ , apply(data.matrixALL, 2, var) != 0]
pca <- prcomp(t(data.matrixALL),scale.=TRUE, center=TRUE)
## calculate the percentage of variation that each PC accounts for...
pca.var <- pca$sdev^2
pca.var.per <- round(pca.var/sum(pca.var)*100, 1)
pca.var.per
## now make a fancy looking plot that shows the PCs and the variation:
pca.data <- data.frame(Sample=rownames(pca$x),
X=pca$x[,1],
Y=pca$x[,2])
pca.data
ggplot(data=pca.data, aes(x=X, y=Y, label=Sample)) +
geom_text() +
xlab(paste("PC1 - ", pca.var.per[1], "%", sep="")) +
ylab(paste("PC2 - ", pca.var.per[2], "%", sep="")) +
theme_bw() +
ggtitle("PCA Graph")
###################################################################
##
## 2) Now draw an MDS plot using the same data and the Euclidean
##    distance. This graph should look the same as the PCA plot
##
###################################################################
## first, calculate the distance matrix using the Euclidian distance.
## NOTE: We are transposing, scaling and centering the data just like PCA.
distance.matrix <- dist(scale(t(data.matrixALL), center=TRUE, scale=TRUE),
method="euclidean")
## do the MDS math (this is basically eigen value decomposition)
mds.stuff <- cmdscale(distance.matrix, eig=TRUE, x.ret=TRUE)
## calculate the percentage of variation that each MDS axis accounts for...
mds.var.per <- round(mds.stuff$eig/sum(mds.stuff$eig)*100, 1)
mds.var.per
## now make a fancy looking plot that shows the MDS axes and the variation:
mds.values <- mds.stuff$points
mds.data <- data.frame(Sample=rownames(mds.values),
X=mds.values[,1],
Y=mds.values[,2])
mds.data
ggplot(data=mds.data, aes(x=X, y=Y, label=Sample)) +
geom_text() +
theme_bw() +
xlab(paste("MDS1 - ", mds.var.per[1], "%", sep="")) +
ylab(paste("MDS2 - ", mds.var.per[2], "%", sep="")) +
ggtitle("MDS plot using Euclidean distance")
###################################################################
##
## 3) Now draw an MDS plot using the same data and the average log(fold change)
##    This graph should look different than the first two
##
###################################################################
## first, take the log2 of all the values in the data.matrixALL.
## This makes it easy to compute log2(Fold Change) between a gene in two
## samples since...
##
## log2(Fold Change) = log2(value for sample 1) - log2(value for sample 2)
##
log2.data.matrixALL <- log2(data.matrixALL)
## now create an empty distance matrix
log2.distance.matrix <- matrix(0,
nrow=ncol(log2.data.matrixALL),
ncol=ncol(log2.data.matrixALL),
dimnames=list(colnames(log2.data.matrixALL),
colnames(log2.data.matrixALL)))
log2.distance.matrix
## now compute the distance matrix using avg(absolute value(log2(FC)))
for(i in 1:ncol(log2.distance.matrix)) {
for(j in 1:i) {
log2.distance.matrix[i, j] <-
mean(abs(log2.data.matrixALL[,i] - log2.data.matrixALL[,j]))
}
}
log2.distance.matrix
## do the MDS math (this is basically eigen value decomposition)
## cmdscale() is the function for "Classical Multi-Dimensional Scalign"
#mds.stuff <- cmdscale(as.dist(log2.distance.matrix),
#  eig=TRUE,
#  x.ret=TRUE)
## calculate the percentage of variation that each MDS axis accounts for...
mds.var.per <- round(mds.stuff$eig/sum(mds.stuff$eig)*100, 1)
mds.var.per
## now make a fancy looking plot that shows the MDS axes and the variation:
mds.values <- mds.stuff$points
mds.data <- data.frame(Sample=rownames(mds.values),
X=mds.values[,1],
Y=mds.values[,2])
mds.data
ggplot(data=mds.data, aes(x=X, y=Y, label=Sample)) +
geom_text() +
theme_bw() +
xlab(paste("MDS1 - ", mds.var.per[1], "%", sep="")) +
ylab(paste("MDS2 - ", mds.var.per[2], "%", sep="")) +
ggtitle("MDS plot using avg(logFC) as the distance")
data.matrixP=read.csv("/Users/jbrown/Documents/GitHub/BACandBlue/stats help and prelim practice/pantoe20181218.csv")
data.matrixF=read.csv("/Users/jbrown/Documents/GitHub/BACandBlue/stats help and prelim practice/otu.csv")
data.matrixALL=merge(data.matrixF,data.matrixP)
head(data.matrixALL)
dim(data.matrixALL)
#data.matrixALL$peaks <- NA #ADD COLUMN FOR NON-ZERO VECTOR TO LAND
#data.matrixALL$peaks[which(data.matrixALL$Peak_ID<=209)] <- "<=209"
data.matrixALL$ï..Peak_ID=as.numeric(data.matrixALL$ï..Peak_ID)
###################################################################
##
## 1) Just for reference, draw a PCA plot using this data...
##
###################################################################
#which(apply(data.matrixALL, 2, var)==0) ##REMOVE THE ZEROS!
#data.matrixALL[ , apply(data.matrixALL, 2, var) != 0]
pca <- prcomp(t(data.matrixALL),scale.=TRUE, center=TRUE)
## calculate the percentage of variation that each PC accounts for...
pca.var <- pca$sdev^2
pca.var.per <- round(pca.var/sum(pca.var)*100, 1)
pca.var.per
## now make a fancy looking plot that shows the PCs and the variation:
pca.data <- data.frame(Sample=rownames(pca$x),
X=pca$x[,1],
Y=pca$x[,2])
pca.data
ggplot(data=pca.data, aes(x=X, y=Y, label=Sample)) +
geom_text() +
xlab(paste("PC1 - ", pca.var.per[1], "%", sep="")) +
ylab(paste("PC2 - ", pca.var.per[2], "%", sep="")) +
theme_bw() +
ggtitle("PCA Graph")
###################################################################
##
## 2) Now draw an MDS plot using the same data and the Euclidean
##    distance. This graph should look the same as the PCA plot
##
###################################################################
## first, calculate the distance matrix using the Euclidian distance.
## NOTE: We are transposing, scaling and centering the data just like PCA.
distance.matrix <- dist(scale(t(data.matrixALL), center=TRUE, scale=TRUE),
method="euclidean")
## do the MDS math (this is basically eigen value decomposition)
mds.stuff <- cmdscale(distance.matrix, eig=TRUE, x.ret=TRUE)
## calculate the percentage of variation that each MDS axis accounts for...
mds.var.per <- round(mds.stuff$eig/sum(mds.stuff$eig)*100, 1)
mds.var.per
## now make a fancy looking plot that shows the MDS axes and the variation:
mds.values <- mds.stuff$points
mds.data <- data.frame(Sample=rownames(mds.values),
X=mds.values[,1],
Y=mds.values[,2])
mds.data
ggplot(data=mds.data, aes(x=X, y=Y, label=Sample)) +
geom_text() +
theme_bw() +
xlab(paste("MDS1 - ", mds.var.per[1], "%", sep="")) +
ylab(paste("MDS2 - ", mds.var.per[2], "%", sep="")) +
ggtitle("MDS plot using Euclidean distance")
###################################################################
##
## 3) Now draw an MDS plot using the same data and the average log(fold change)
##    This graph should look different than the first two
##
###################################################################
## first, take the log2 of all the values in the data.matrixALL.
## This makes it easy to compute log2(Fold Change) between a gene in two
## samples since...
##
## log2(Fold Change) = log2(value for sample 1) - log2(value for sample 2)
##
log2.data.matrixALL <- log2(data.matrixALL)
## now create an empty distance matrix
log2.distance.matrix <- matrix(0,
nrow=ncol(log2.data.matrixALL),
ncol=ncol(log2.data.matrixALL),
dimnames=list(colnames(log2.data.matrixALL),
colnames(log2.data.matrixALL)))
log2.distance.matrix
## now compute the distance matrix using avg(absolute value(log2(FC)))
for(i in 1:ncol(log2.distance.matrix)) {
for(j in 1:i) {
log2.distance.matrix[i, j] <-
mean(abs(log2.data.matrixALL[,i] - log2.data.matrixALL[,j]))
}
}
log2.distance.matrix
## do the MDS math (this is basically eigen value decomposition)
## cmdscale() is the function for "Classical Multi-Dimensional Scalign"
#mds.stuff <- cmdscale(as.dist(log2.distance.matrix),
#  eig=TRUE,
#  x.ret=TRUE)
## calculate the percentage of variation that each MDS axis accounts for...
mds.var.per <- round(mds.stuff$eig/sum(mds.stuff$eig)*100, 1)
mds.var.per
## now make a fancy looking plot that shows the MDS axes and the variation:
mds.values <- mds.stuff$points
mds.data <- data.frame(Sample=rownames(mds.values),
X=mds.values[,1],
Y=mds.values[,2])
mds.data
ggplot(data=mds.data, aes(x=X, y=Y, label=Sample)) +
geom_text() +
theme_bw() +
xlab(paste("MDS1 - ", mds.var.per[1], "%", sep="")) +
ylab(paste("MDS2 - ", mds.var.per[2], "%", sep="")) +
ggtitle("MDS plot using avg(logFC) as the distance")
View(mds.data)
knitr::opts_chunk$set(echo = TRUE)
##what you need to install phyloseq
#source('http://bioconductor.org/biocLite.R')
#biocLite('phyloseq')
library(ggplot2)
library(beeswarm)
library(phyloseq) #install via bioconductor
library(vegan)
library(ggbiplot)
library(readxl)
library(readr)
library(ape)
# read in data
meta <- read.csv("/Users/jbrown/Documents/GitHub/BACandBlue/data/20181219_FF AND PA IN BBJ/meta.csv")
meta$hour=as.factor(meta$hour)
rownames(meta) <- meta$SampleID_merge
SAMP <- sample_data(meta)
sample_names(SAMP)<-meta$SampleID
peaks <- read.csv("/Users/jbrown/Documents/GitHub/BACandBlue/data/20181219_FF AND PA IN BBJ/peak.csv")
TAX <- tax_table(peaks) # gives a warning, don't freak out
taxa_names(TAX)<-peaks$Peak_ID
colnames(TAX)<- colnames(peaks)
abund <- read.csv("/Users/jbrown/Documents/GitHub/BACandBlue/data/20181219_FF AND PA IN BBJ/otu.csv", colClasses = c("factor","factor", rep("numeric", times=48)))
# read in peak areas, assigning factors of diff classifications based on columns
rownames(abund) <- abund$Peak_ID #give abund rows names according to "Peak_ID" in peak.csv table
OTU <- otu_table(abund[,-c(1:2)], taxa_are_rows=T) #create a table with only peak areas, compounds are taxa
VOC <- phyloseq(OTU, TAX, SAMP)
# returns: "phyloseq-class experiment-level object
#otu_table()   OTU Table:         [ 27 taxa and 75 samples ]
#sample_data() Sample Data:       [ 75 samples by 8 sample variables ]
#tax_table()   Taxonomy Table:    [ 27 taxa by 2 taxonomic ranks ]"
###############################
# Analysis and figures
##############################
##############
#    PCoAs   #
##############
#
##
###	#PCoA with Bray-Curtis Distances#	###
ord <- ordinate(VOC, method = "PCoA", distance = "bray")
plot_ordination(VOC, ord, color = "hour", shape = "microbe", label = "rep")
plot_ordination(VOC, ord, type = "samples", color = "hour", shape = "microbe", label = "rep")
PCs <- data.frame(scores(ord$vectors))
new.dat <- cbind(PCs, sample_data(VOC)$microbe, sample_data(VOC)$rep, sample_data(VOC)$hour) # make a new matrix
names(new.dat)[32:34] <- c("microbe","rep","hour")
library(gdata)
new.dat$Microbe <- reorder.factor(new.dat$microbe, new.order = c("FF", "PA"))
new.dat$Hour <- reorder.factor(new.dat$hour, new.order = c("2","24","48"))
ggplot(new.dat, aes(x=Axis.1, y= Axis.2)) +
geom_point(aes(color = Microbe, shape = Hour), position ="jitter") +
facet_grid(~Hour)+
theme_bw()+
xlab("PCoA1 (33.5% Var. Expl.)")+ 	## !don't forget to update these moving forward!
ylab("PCoA2 (25.4% Var. Expl.)")
###
##
#
#
##
###	#PCoA with Jaccard distances#	###
ord <- ordinate(VOC, method = "PCoA", distance = "jaccard", binary = TRUE)
plot_ordination( VOC, ord, color = "hour", shape = "microbe", type = "samples")
# split plot of compounds driving separation and samples in PC1/PC2.
plot_ordination(VOC, ord, type = "samples", color = "hour", shape = "microbe", label = "rep")
###
###
PCs <- data.frame(scores(ord$vectors))
new.dat <- cbind(PCs, sample_data(VOC)$microbe, sample_data(VOC)$hour, sample_data(VOC)$rep) # make a new matrix
names(new.dat)[32:34] <- c("Microbe", "Hour", "Rep")
library(gdata)
new.dat$Microbe <- reorder.factor(new.dat$Microbe, new.order = c("FF", "PA"))
new.dat$Hour <- reorder.factor(new.dat$Hour, new.order = c("2","24", "48"))
###
###
ggplot(new.dat, aes(x=Axis.1, y= Axis.2)) +
geom_point(aes(color = Microbe, shape = Hour), position ="jitter") +
facet_grid(~Hour)+
theme_bw()+
xlab("PCoA1 (40.9% Var. Expl.)")+
ylab("PCoA2 (25% Var. Expl.)")
